{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9 - Linear Models - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will make all the `matplotlib` images appear in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions\n",
    "\n",
    "The due dates for each are indicated in the Syllabus and the course calendar. If anything is unclear, please email EN685.648@gmail.com the official email for the course or ask questions in the Lab discussion area on Blackboard.\n",
    "\n",
    "The Labs also present technical material that augments the lectures and \"book\".  You should read through the entire lab at the start of each module.\n",
    "\n",
    "<div style=\"background: mistyrose; color: firebrick; border: 2px solid darkred; padding: 5px; margin: 10px;\">\n",
    "Please follow the directions and make sure you provide the requested output. Failure to do so may result in a lower grade even if the code is correct or even 0 points.\n",
    "</div>\n",
    "\n",
    "### General Instructions\n",
    "\n",
    "1.  You will be submitting your assignment to Blackboard. If there are no accompanying files, you should submit *only* your notebook and it should be named using *only* your JHED id: fsmith79.ipynb for example if your JHED id were \"fsmith79\". If the assignment requires additional files, you should name the *folder/directory* your JHED id and put all items in that folder/directory, ZIP it up (only ZIP...no other compression), and submit it to Blackboard.\n",
    "    \n",
    "    * do **not** use absolute paths in your notebooks. All resources should appear in the same directory as the rest of your assignments.\n",
    "    * the directory **must** be named your JHED id and **only** your JHED id.\n",
    "    * you don't need to submit course supplied data sets back.\n",
    "    \n",
    "2. Data Science is as much about what you write (communicating) as the code you execute (researching). In many places, you will be required to execute code and discuss both the purpose and the result. Additionally, Data Science is about reproducibility and transparency. This includes good communication with your team and possibly with yourself. Therefore, you must show **all** work.\n",
    "\n",
    "3. Avail yourself of the Markdown/Codecell nature of the notebook. If you don't know about Markdown, look it up. Your notebooks should not look like ransom notes. Don't make everything bold. Clearly indicate what question you are answering.\n",
    "\n",
    "4. Submit a cleanly executed notebook. The first code cell should say `In [1]` and each successive code cell should increase by 1 throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data\n",
    "\n",
    "It's very important to understand the underlying data generated by the model you're building and to understand how the algorithm you're using to build the model works. Both of these ends can be accomplished by generating synthetic data and then trying to see if you can recover the \"correct\" model you used to generate the data.\n",
    "\n",
    "Generate the following synthetic data sets and model them with the appropriate linear model from the chapter. You can also refer to the chapter to see how to generate the synthetic data (as well as previous labs).\n",
    "\n",
    "For each of these, save a different random seed. *You may wish to develop each of these models in a separate notebook and then copy them, when done, into your final Lab notebook.*\n",
    "\n",
    "**Linear Regression**\n",
    "\n",
    "1. Generate a model $\\beta_0 + \\beta_1 x_1$ where $x_1 \\sim N(50.0, \\sigma)$. Pick your own $\\beta_0$ and $\\beta_1$ but chose $\\sigma$ so that the $R^2$ is around 0.60.\n",
    "2. Generate a model $\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 \\times x_2$ where $x_1 ~ N(50.0, \\sigma)$ and $x_2 ~ Bernouilli(p)$. Pick your own $\\beta_i$ and $p$ but pick $\\sigma$ so that $R^2$ is around 0.8.\n",
    "3. Create a model of your own choosing that explores a relationship or concept that you're curious about (for example, how do $\\sigma$ and $R^2$ relate?)\n",
    "\n",
    "\n",
    "**Logistic Regression**\n",
    "\n",
    "1. Generate a model $\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 \\times x_2$ where $x_1 ~ N(50.0, 5.0)$ and $x_2 ~ Bernouilli(0.67)$. Pick your own $\\beta_i$ but try to get the error rate to be 15% or lower.\n",
    "2. Create a model of your own choosing that explores a relationship or concept that you're curious about.\n",
    "\n",
    "For each of these, you may use the \"normal\" versions of the functions (non-bootstrap) to explore the problem and parameters but your final model should be the bootstrap version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Linear Regression\n",
    "**1)**\n",
    "$ \\beta_0 + \\beta_1 x_1 $ where $x_1 \\sim N(50.0, \\sigma)$ pick your own $\\beta_0$ and $\\beta_1$ but chose $\\sigma$ so that the $R^2$ is around 0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "    <tr><th> model </th><td> y ~ x1 </td></tr>\n",
       "    <tr><th colspan=2>coefficients</th></tr>\n",
       "    <tr><th> $\\beta_0$ </th><td> 5.5339486999782075 </td></tr><tr><td>  x1 ($\\beta_1$) </td><td> 0.899719987809989 </td></tr>\n",
       "    <tr><th colspan=2>metrics</th></tr>\n",
       "    <tr><td> $\\sigma$ </td><td> 66.46925914628838 </td></tr>\n",
       "    <tr><td> $R^2$ </td><td> 0.6042055330796183 </td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "data = {}\n",
    "data[\"β0\"] = 0\n",
    "data[\"β1\"] = 1\n",
    "data[\"μ\"] = 50.0\n",
    "data[\"σ\"] = 70\n",
    "data[\"x1\"] = stats.norm.rvs(loc = data[\"μ\"], scale = 100, size = 100)\n",
    "data[\"e\"] = stats.norm.rvs(loc = 0, scale = data[\"σ\"], size = 100)\n",
    "data[\"y\"] = data[\"β0\"] + data[\"β1\"]*data[\"x1\"] + data[\"e\"]\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "result1 = models.linear_regression( \"y ~ x1\", data = data)\n",
    "models.simple_describe_lr(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "    <tr><th> model </th><td> y ~ x1 </td></tr>\n",
       "    <tr><th colspan=2>coefficients</th><th>95% BCI</th></tr>\n",
       "    <tr><th> $\\beta_0$ </th><td> 5.53 </td><td>(-9.18, 21.08)</td></tr><tr><td>  x1 ($\\beta_1$) </td><td> 0.90 </td><td>(0.76, 1.06)</tr><tr><th colspan=2>metrics</th><th>95% BCI</th></tr><tr><th> $\\sigma$ </th><td> 66.47 </td><td>(57.00, 73.97) </td></tr><tr><th> $R^2$ </th><td> 0.60 </td><td>(0.47, 0.72)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = models.bootstrap_linear_regression(\"y ~ x1\", data=data, samples=1_000)\n",
    "models.describe_bootstrap_lr(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of bootstrapped linear regression on this data is the estimated model\n",
    "$$ \\hat{y} = 5.53 + 0.90 x $$\n",
    "where the actual model was\n",
    "$$ y = 0 + 1x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**2)** Generate a model $\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 \\times x_2$ where $x_1 \\sim N(50.0, \\sigma)$ and $x_2 \\sim Bernouilli(p)$. Pick your own $\\beta_i$ and $p$ but pick $\\sigma$ so that $R^2$ is around 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "    <tr><th> model </th><td> y ~ x1 + x2 + x1:x2 </td></tr>\n",
       "    <tr><th colspan=2>coefficients</th></tr>\n",
       "    <tr><th> $\\beta_0$ </th><td> 15.076182763884633 </td></tr><tr><td>  x1  ($\\beta_1$) </td><td> 1.9769502874824938 </td></tr><tr><td>  x2  ($\\beta_2$) </td><td> -4.548458692979197 </td></tr><tr><td>  x1:x2 ($\\beta_3$) </td><td> -1.753547181391942 </td></tr>\n",
       "    <tr><th colspan=2>metrics</th></tr>\n",
       "    <tr><td> $\\sigma$ </td><td> 76.45111086429799 </td></tr>\n",
       "    <tr><td> $R^2$ </td><td> 0.8281822118050532 </td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "data = {}\n",
    "data[\"β0\"] = 0\n",
    "data[\"β1\"] = 2\n",
    "data[\"β2\"] = 10\n",
    "data[\"β3\"] = -2\n",
    "\n",
    "data[\"μ\"] = 50.0\n",
    "data[\"x1\"] = stats.norm.rvs(loc = data[\"μ\"], scale = 100, size = 100)\n",
    "data[\"x2\"] = stats.bernoulli.rvs(0.25, size = 100)\n",
    "\n",
    "data[\"σ\"] = 75\n",
    "data[\"e\"] = stats.norm.rvs(loc = 0, scale = data[\"σ\"], size = 100)\n",
    "\n",
    "data[\"y\"] = data[\"β0\"] + data[\"β1\"]*data[\"x1\"] + data[\"β2\"]*data[\"x2\"] + data[\"β3\"]*data[\"x1\"]*data[\"x2\"] + data[\"e\"]\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "result1 = models.linear_regression( \"y ~ x1 + x2 + x1:x2\", data = data)\n",
    "models.simple_describe_lr(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "    <tr><th> model </th><td> y ~ x1 + x2 + x1:x2 </td></tr>\n",
       "    <tr><th colspan=2>coefficients</th><th>95% BCI</th></tr>\n",
       "    <tr><th> $\\beta_0$ </th><td> 15.08 </td><td>(-5.94, 34.41)</td></tr><tr><td>  x1  ($\\beta_1$) </td><td> 1.98 </td><td>(1.79, 2.18)</tr><tr><td>  x2  ($\\beta_2$) </td><td> -4.55 </td><td>(-36.69, 31.18)</tr><tr><td>  x1:x2 ($\\beta_3$) </td><td> -1.75 </td><td>(-2.05, -1.45)</tr><tr><th colspan=2>metrics</th><th>95% BCI</th></tr><tr><th> $\\sigma$ </th><td> 76.45 </td><td>(63.92, 86.56) </td></tr><tr><th> $R^2$ </th><td> 0.83 </td><td>(0.76, 0.88)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = models.bootstrap_linear_regression( \"y ~ x1 + x2 + x1:x2\", data = data, samples = 1_000)\n",
    "models.describe_bootstrap_lr(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated model is\n",
    "$$ \\hat{y} = 15.08 + 1.98 x_1 - 4.55 x_2 - 1.75 x_1 x_2 $$\n",
    "and the desired model was\n",
    "$$ y = 0 + 2 x_1 + 10 x_2 - 2 x_1 x_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**3)** Create a model of your own choosing that explores a relationship or concept that you're curious about (for example, how do $\\sigma$ and $R^2$ relate?)\n",
    "\n",
    "I'm interested in how regression works when all of the regressors are categorical or from a bernoulli distribution. To examine this, I will try a distribution with two bernoulli distributions.\n",
    "$$ \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 $$\n",
    "Where $x_1 \\sim Bernouilli(0.5)$ and $x_2 \\sim Bernouilli(0.1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "    <tr><th> model </th><td> y ~ x1 + x2 </td></tr>\n",
       "    <tr><th colspan=2>coefficients</th></tr>\n",
       "    <tr><th> $\\beta_0$ </th><td> 0.4572961562501266 </td></tr><tr><td>  x1  ($\\beta_1$) </td><td> 2.9034689515962184 </td></tr><tr><td>  x2 ($\\beta_2$) </td><td> 9.44613507697176 </td></tr>\n",
       "    <tr><th colspan=2>metrics</th></tr>\n",
       "    <tr><td> $\\sigma$ </td><td> 70.06585375006817 </td></tr>\n",
       "    <tr><td> $R^2$ </td><td> 0.8816361612084294 </td></tr>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "data = {}\n",
    "data[\"β0\"] = 0\n",
    "data[\"β1\"] = 3\n",
    "data[\"β2\"] = 10\n",
    "\n",
    "data[\"x1\"] = stats.bernoulli.rvs(0.50, size = 100) * 100\n",
    "data[\"x2\"] = stats.bernoulli.rvs(0.10, size = 100) * 50\n",
    "\n",
    "data[\"σ\"] = 75\n",
    "data[\"e\"] = stats.norm.rvs(loc = 0, scale = data[\"σ\"], size = 100)\n",
    "\n",
    "data[\"y\"] = data[\"β0\"] + data[\"β1\"]*data[\"x1\"] + data[\"β2\"]*data[\"x2\"] + data[\"e\"]\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "result1 = models.linear_regression( \"y ~ x1 + x2\", data = data)\n",
    "models.simple_describe_lr(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table>\n",
       "    <tr><th> model </th><td> y ~ x1 + x2 </td></tr>\n",
       "    <tr><th colspan=2>coefficients</th><th>95% BCI</th></tr>\n",
       "    <tr><th> $\\beta_0$ </th><td> 0.46 </td><td>(-17.83, 17.76)</td></tr><tr><td>  x1  ($\\beta_1$) </td><td> 2.90 </td><td>(2.63, 3.20)</tr><tr><td>  x2 ($\\beta_2$) </td><td> 9.45 </td><td>(8.53, 10.39)</tr><tr><th colspan=2>metrics</th><th>95% BCI</th></tr><tr><th> $\\sigma$ </th><td> 70.07 </td><td>(60.29, 78.29) </td></tr><tr><th> $R^2$ </th><td> 0.88 </td><td>(0.83, 0.92)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = models.bootstrap_linear_regression( \"y ~ x1 + x2\", data = data, samples = 1_000)\n",
    "models.describe_bootstrap_lr(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$x_2$')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.scatter(x = data.x1, y = data.y)\n",
    "ax1.set_xlabel(\"$x_1$\")\n",
    "ax1.set_ylabel(\"$y$\")\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n",
    "ax2.scatter(x = data.x2, y = data.y)\n",
    "ax2.set_xlabel(\"$x_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, it seems that given sufficiently \"good\" data, regression works quite well in predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Logistic Regression\n",
    "**1)** Generate a model $\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 \\times x_2$ where $x_1 \\sim N(50.0, 5.0)$ and $x_2 \\sim Bernouilli(0.67)$. Pick your own $\\beta_i$ but try to get the error rate to be 15% or lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c7bfafd465e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"y ~ x1 + x2 + x1:x2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_describe_lgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Masters/en_685_648_data_science/9_module/lab/models.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(formula, data)\u001b[0m\n\u001b[1;32m     58\u001b[0m     )  # not sure why this is needed for LogisticRegression but not LinearRegression\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/en685648/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/en685648/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "data = {}\n",
    "data[\"β0\"] = 0\n",
    "data[\"β1\"] = 2\n",
    "data[\"β2\"] = 10\n",
    "data[\"β3\"] = 5\n",
    "\n",
    "data[\"x1\"] = stats.norm.rvs(loc = 50.0, scale = 5.0, size = 100)\n",
    "data[\"x2\"] = stats.bernoulli.rvs(0.67, size = 100)\n",
    "\n",
    "data[\"σ\"] = 5\n",
    "data[\"e\"] = stats.norm.rvs(loc = 0, scale = data[\"σ\"], size = 100)\n",
    "\n",
    "data[\"y\"] = data[\"β0\"] + data[\"β1\"]*data[\"x1\"] + data[\"β2\"]*data[\"x2\"] + data[\"β3\"]*data[\"x1\"]*data[\"x2\"] + data[\"e\"]\n",
    "# data[\"y\"] = data[\"x1\"]\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "result1 = models.logistic_regression( \"y ~ x1 + x2 + x1:x2\", data = data)\n",
    "models.simple_describe_lgr(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**2)** Create a model of your own choosing that explores a relationship or concept that you're curious about"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "171px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
