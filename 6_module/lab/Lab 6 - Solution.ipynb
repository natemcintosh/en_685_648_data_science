{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 - Mathematical Distributions - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will make all the `matplotlib` images appear in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions\n",
    "\n",
    "**Failure to follow the directions will result in a \"0\"**\n",
    "\n",
    "The due dates for each are indicated in the Syllabus and the course calendar. If anything is unclear, please email EN685.648@gmail.com the official email for the course or ask questions in the Lab discussion area on Blackboard.\n",
    "\n",
    "The Labs also present technical material that augments the lectures and \"book\".  You should read through the entire lab at the start of each module.\n",
    "\n",
    "### General Instructions\n",
    "\n",
    "1.  You will be submitting your assignment to Blackboard. If there are no accompanying files, you should submit *only* your notebook and it should be named using *only* your JHED id: fsmith79.ipynb for example if your JHED id were \"fsmith79\". If the assignment requires additional files, you should name the *folder/directory* your JHED id and put all items in that folder/directory, ZIP it up (only ZIP...no other compression), and submit it to Blackboard.\n",
    "    \n",
    "    * do **not** use absolute paths in your notebooks. All resources should appear in the same directory as the rest of your assignments.\n",
    "    * the directory **must** be named your JHED id and **only** your JHED id.\n",
    "    \n",
    "2. Data Science is as much about what you write (communicating) as the code you execute (researching). In many places, you will be required to execute code and discuss both the purpose and the result. Additionally, Data Science is about reproducibility and transparency. This includes good communication with your team and possibly with yourself. Therefore, you must show **all** work.\n",
    "\n",
    "3. Avail yourself of the Markdown/Codecell nature of the notebook. If you don't know about Markdown, look it up. Your notebooks should not look like ransom notes. Don't make everything bold. Clearly indicate what question you are answering.\n",
    "\n",
    "4. Submit a cleanly executed notebook. It should say `In [1]` for the first codecell and increase by 1 throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ee0c3209dfc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp_random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as py_random\n",
    "import numpy.random as np_random\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Samples from Probability Distributions\n",
    "\n",
    "Doctors work on cadavers and other professionals learn on similar, if less gruesome, models. For data scientists, we have at our disposal an infinite amount of synthetic data. The next questions introduce you to this technique in the form of random numbers and mathematical distributions.\n",
    "\n",
    "### Reproducible Random Numbers\n",
    "\n",
    "Before you begin working with random numbers in any situation, in Data Science, as opposed to Machine Learning, it is desirable to set the random seed and record it. We do this for several reasons:\n",
    "\n",
    "1. For reproducible research, we need to record the random seed that was used to generate our results so they will be regenerated exactly the same.\n",
    "2. For sharing with others, if our text said there was some result, and the user re-runs the notebook, we want to get the same results.\n",
    "3. If we are creating a model, and we accidentally generate the best model ever, we want to be able to build it again.\n",
    "\n",
    "Although Python has *some* random number generators, we will be using `NumPy`'s random number generators throughout the course because it has a broader range of distributions.\n",
    "\n",
    "```\n",
    "np.random.seed(N) # Numpy library\n",
    "```\n",
    "\n",
    "You have several options for setting the seed:\n",
    "\n",
    "* Just come up with a number, some integer, like: 27192759.\n",
    "* Run:\n",
    "\n",
    "```\n",
    "    int( time.time())\n",
    "```\n",
    "\n",
    "to print out a value you can use in either case. Do not just feed `int( time.time())` into the seed function. The whole point is to make the seed a constant. Numpy has ample documentation on its [random module](https://docs.scipy.org/doc/numpy/reference/routines.random.html).\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int( time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([1482004723]) # note the use of a number iside a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the two above don't match. They did the very first time I ran the notebook but they don't now because I've had to re-run the notebook several times. This is, in fact, the point. In fact, in general, once you execute `int( time.time())` to get your seed, you can just delete the cell or just make up a seed. I like to use my birthday: YYYYMMDD and variations of other dates (don't use the same seed for *everything*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(10)\n",
    "# do some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand( 10)\n",
    "# do more stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([1482004723])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(10)\n",
    "# do some stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to note here:\n",
    "\n",
    "1. We asked what time it was to get the seed but we did not put it directionly into `np.random.seed()`.\n",
    "2. The argument to `np.random.seed()` must be a List.\n",
    "3. We set the seed then got 10 random numbers by calling `np.random.rand(10)`. In practice, this might just be all we want to do (get numbers from the distribution) or we may want to do more calculations.\n",
    "4. We get 10 more random numbers by calling `np.random.rand( 10)`. Notice that these are not the same as the first call. You can think of `random` *in general* as generating a stream of random numbers according to some distribution which we just tap into. We get the first 10, the next 10, the next 25, etc.\n",
    "5. We set the random seed to the same random seed as before.\n",
    "6. We got the same first 10 random numbers. This demonstrates that setting the seed \"resets\" the stream of random numbers. This is what we want.\n",
    "\n",
    "In general, before answering each question, we are going to want to set the random seed to some value. Do not do it inside a function that is getting called over and over again, set it at the start of the experiment.\n",
    "\n",
    "We will talk a lot more about visualization later but for right now I'm going to introduce the *histogram*. A histogram is a means for visualizing the distribution of a variable. There are several variants and the libraries are sometimes confusing on this score. Absent any directions to the contrary, the histogram will calculate the absolute counts of the data. The usual alternative, at least with continuous variables, is to set `normed=True` and you will get a *density*. It is also possible through weigting to get a `mass` or *relative frequency* for a discrete variable.\n",
    "\n",
    "## Uniform Distribution\n",
    "\n",
    "Consider the following problem. I want to generate 100 data points on the range (-5.0, 10.0) that are from a *uniform distribution*. How do I do this?\n",
    "\n",
    "1. I set the random seed.\n",
    "2. I look through the documentation to see if there is a function that will generate the data directly or via a *transformation*.\n",
    "3. I then visualize the data I generated.\n",
    "\n",
    "Let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int( time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([1482003424]) # this will be different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the documentation, there is a function `uniform` that takes *low*, *high* and *size* arguments. Let's do it that way first. I'm going to arbitrarily look at the first 20 values just to see what I got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.random.uniform(-5.0, 10.0, 100)\n",
    "print( xs[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I'm going to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 6)) # first element is width, second is height.\n",
    "\n",
    "axes = figure.add_subplot(1, 1, 1)\n",
    "\n",
    "axes.hist( xs, density=True, color=\"DimGray\") # a density\n",
    "axes.set_ylabel( \"Density\")\n",
    "axes.set_xlabel( \"X\")\n",
    "axes.set_title( \"Density for Uniform Distribution (-5.0, 10.0)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also going to explore the data a little bit. I used the parameters *low* and *high* to generate the data. What values did I get back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"low =\", min( xs))\n",
    "print( \"high=\", max( xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating the synthetic data as an *empirical distribution*, I can also calculate the moments of the data. However, there aren't `m1` or `m2` functions. Instead, I'm going to use the identity between `m1` and the *arithmetic mean* and `m2` and the variance but I am not going to commit any particular Mathematical distribution as a model for this data even though I know that I used a Uniform distribution to generate it.\n",
    "\n",
    "This last point can be a bit confusing. I would say all software packages and libraries will calculate the mean and variance but this is actually conflating two steps: calculating the first two moments and using those moments to parameterize a Mathematical distribution as a model (mean and variance). This is mostly because of the Central Limit Theorem which indicates that we are going to run into the Normal distribution a lot of the time but it is still combining *two steps*. As data scientists, we want to pull these two steps apart and make our own judgements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"m1=\", np.mean(xs))\n",
    "print( \"m2=\", np.var( xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if `uniform` hadn't existed? I would have had to have used `random` which generates uniformly distributed random numbers on the range (0, 1) and projected it into the range (-5.0, 10.0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([1482003424])\n",
    "xs = np.random.random(100) * 15.0 - 5.0\n",
    "print( xs[0:20])\n",
    "print( \"low =\", min( xs))\n",
    "print( \"high=\", max( xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a *new* experiment so I set the random seed. However, I specifically wanted to see if the two different methods generated the same random numbers (they do) so I set it the same random seed. In general, each experiment will have a different random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises.\n",
    "\n",
    "**1\\. A coin has a probability of heads, $\\theta=0.67$. Simulate 25 events (coin tosses) from this Bernouilli distribution (25 Bernoulli *Trials*).**\n",
    "\n",
    "1. Set the random seed.\n",
    "2. Generate the samples, `x`. (There may be multiple ways to do this).\n",
    "3. Calculate the first moment using `np.mean( x)` to get the estimate of $p$ (it's a Python trick). How close are you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 1. ** Set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([125]) # made this up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 2\\.** Calculate the data. We can use $\\theta$ as a threshold value against a uniformly distributed variable on the range (0, 1) to simulate a Bernoulli trial. We indicate 1 for success and 0 for failure. This is a \"roll your own\" method using a *List Comprehension*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.67\n",
    "xs = [1 if np.random.random() < theta else 0 for _ in range( 25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3\\.** We can use `np.mean` over the 0's and 1's to get $m_1$ which is then the Method of Moments estimator for $\\theta$. We can compare this to the $\\theta$ we started with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.mean( xs)\n",
    "print( \"m1 = theta_hat =\", m1)\n",
    "print( \"theta_hat/theta =\", m1/theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very close (0.72/0.67) is more than 7% higher than it \"really\" was. We'll see in the next Module what this means and how to bound our estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Working with the Normal Distribution.**\n",
    "\n",
    "**2\\. $\\mu=32.5$ and $\\sigma=0.325$**\n",
    "\n",
    "1. Set the random seed.\n",
    "2. Find the function for the normal distribution in the NumPy documentation.\n",
    "3. Generate **25** samples for $x$ from a normal distribution with $\\mu=32.5$ and $\\sigma=0.325$ (1%). \n",
    "4. Plot a histogram of the data (change the labels!)\n",
    "5. Calculate the first moment of $x$.\n",
    "6. Using the Method of Moments, estimate the mean from the first moment. How far off is your estimate in percent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1\\.** Set the random seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([12873])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2\\.** Looking in the documentation for NumPy, the function that creates random numbers from the normal distribution is:\n",
    "\n",
    "`normal([loc, scale, size])`\n",
    "\n",
    "where loc = mu, scale = standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3\\.** Let's make a function to translate mu and v into s (standard deviation) and then use the function to create 25 samples from a normal distribution with the specified parameters. We're going to print out 20 just to get a sense of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 32.5\n",
    "s = 0.325\n",
    "xs = np.random.normal( mu, s, 25)\n",
    "print(xs[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4\\.** Plot the data we just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 6)) # first element is width, second is height.\n",
    "\n",
    "axes = figure.add_subplot(1, 1, 1)\n",
    "\n",
    "axes.hist( xs, density=True, color=\"DimGray\")\n",
    "axes.set_ylabel( \"Density\")\n",
    "axes.set_xlabel( \"X\")\n",
    "axes.set_title( \"Density for Normal Distribution (%0.2f, %0.2f)\" % ( mu, s))\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks normally distributed, kind of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5\\.** Print out the first moment using `np.mean(xs)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.mean( xs)\n",
    "print( \"m1 =\", m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6\\.** Calculate the discrepancy. In this case, $m_1$ is the estimate of the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"discrepancy =\", m1/mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discrepancy isn't very much with the amount of variability we used (1% of the mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one of the problems with this experiment is that we only run it once. We might run it and the mean will only be 1% off and we might run it again (with a different seed) and the results are 10% off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3\\. Rerunning experiments **\n",
    "\n",
    "1. Set the random seed.\n",
    "2. Write a function that will generate *m* samples of $x$ from the Normal distribution, *n* times. This means the function will return a List of Lists. The outer List will have length *n* and the inner Lists will all have length *m*. Use the $\\mu$ and $\\sigma$ from the previous exercise. Set *m* = 25 and *n* = 100 (you'll then have 100 data sets, each with 25 data points).\n",
    "3. Calculate the first moment of each of the *n* data sets.  You'll have 100 of these.\n",
    "3. Plot a histogram of the data.\n",
    "4. Calculate the low, high and first moment of the data and discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1\\.** Set the random seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([3841765259])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2\\.** Write a function that will run the previous experiment multiple times. mu is the mean, v is the coefficient of variation, m is the number of samples, n is the number of trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_random_normal( mu, s, m, n,):\n",
    "    result = []\n",
    "    for i in range( n):\n",
    "        xs = np.random.normal( mu, s, m)\n",
    "        m1 = np.mean( xs)\n",
    "        result.append( m1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 32.5\n",
    "s = 0.325\n",
    "m = 25\n",
    "n = 100\n",
    "\n",
    "xs = repeat_random_normal( mu, s, 25, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our $xs$ are themselves calculations of first moments! We can apply these techniques to our estimates and just analyze them as data.\n",
    "\n",
    "**Step 3\\.** Plot a histogram of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 6)) # first element is width, second is height.\n",
    "\n",
    "axes = figure.add_subplot(1, 1, 1)\n",
    "\n",
    "axes.hist( xs, density=True, color=\"DimGray\")\n",
    "axes.set_ylabel( \"Density\")\n",
    "axes.set_xlabel( \"X\")\n",
    "axes.set_title( \"Density for Mean of %d Samples from a Normal Distribution (%0.2f, %0.2f)\" % ( n, mu, s))\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4\\.** Calculate the low, high and mean of the data and discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"low =\", np.min( xs))\n",
    "print( \"m1 =\", np.mean( xs))\n",
    "print( \"high =\", np.max( xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can see that the range of means calculated from the data match the actual mean (mu) very well. This depends mostly on the fact that the variability (dispersion) is so low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Distributions\n",
    "\n",
    "As we saw in the chapter \"Mathematical Distributions\", while the Normal distribution is parameterized by the mean and variance (standard deviation), other distributions are not. We would like to see what data from other distributions looks like whose first moment is about 32.5 (and whose second moment is about 0.325, if appropriate).\n",
    "\n",
    "How can we do this? Well, we can cheat a little.\n",
    "\n",
    "We can use the Method of Moments to move from our value of $\\mu$ from Exercise 2 to the first moment $m_1$ and then the appropriate formulas to move to the parameters of whatever Mathematical distribution we want. Similarly, we can move from $\\sigma^2$ to $m_2$ and then use that as the second moment if needed.\n",
    "\n",
    "The Method of Moments formulas for various distributions are provided in the text. If you should need formulas for other distributions, you can either search for them or derive them yourself.\n",
    "\n",
    "**4\\. Exponentional Distribution**\n",
    "\n",
    "Based on this discussion, use $\\mu = 32.5$ and $\\sigma = 0.325$ to generate 25 samples from the Exponential distribution and repeat the same steps we did for the Normal distribution. Remember, you need to convert these into $m_1$ and $m_2$ and then $m_1$ and $m_2$ (if needed) into the parameter(s) you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1\\.** Set random seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([13579])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 2\\.** Find the function in the documentation:\n",
    "\n",
    "`exponential(scale=1.0, size=None)`\n",
    "\n",
    "We know from the text that the Exponential distribution is \"officially\" parameterized by $\\lambda$, the rate. These kinds of mismatches often happen. Because $scale = \\beta = \\frac{1}{\\lambda}$, we can use $\\mu \\rightarrow m_1 \\rightarrow scale$ directly. $m_2$ is not used.\n",
    "\n",
    "(Remember that if $\\beta$, the scale, is 2 calls per hour then $\\lambda$, the rate, is 30 minutes between calls.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3\\.** Generate samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 32.5\n",
    "xs = np.random.exponential( mu, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 4\\.** Plot the data. Even though we used $\\mu$, we're going to put $\\lambda$ in the title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 6)) # first element is width, second is height.\n",
    "\n",
    "axes = figure.add_subplot(1, 1, 1)\n",
    "\n",
    "axes.hist( xs, density=True, color=\"DimGray\")\n",
    "axes.set_ylabel( \"Density\")\n",
    "axes.set_xlabel( \"X\")\n",
    "axes.set_title( \"Density for Exponential Distribution (rate=%0.3f)\" % (1/mu))\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 5\\.** Print out the mean (the first moment) although we're really interested in the rate parameter, $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.mean( xs)\n",
    "rate = 1/m1\n",
    "\n",
    "print( \"m1 =\", m1)\n",
    "print( \"rate =\", rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6\\.** How far off is the mean you calculate from the $\\mu$ you started off with (in percent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"discrepancy =\", m1/mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discrepancy is about 10% which is quite a bit bigger than when we used the same number to parameterize a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5\\. Gamma Distribution**\n",
    "\n",
    "Based on the discussion above, use $\\mu = 32.5$ and $\\sigma = 0.325$ to generate 25 samples from the Gamma distribution and repeat the same steps we did for the Normal distribution. Remember, you need to convert these into $m_1$ and $m_2$ and then $m_1$ and $m_2$ (if needed) into the parameter(s) you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1\\.** Set random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed([683920])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 2\\.** Find the function in the documentation. \n",
    "\n",
    "The function from the documentation is here:\n",
    "\n",
    "`gamma(shape, scale=1.0, size=None)¶`\n",
    "\n",
    "I found the formula for the Method of Moments estimators [here](http://www.itl.nist.gov/div898/handbook/eda/section3/eda366b.htm). They are:\n",
    "\n",
    "$$\\gamma = (\\frac{\\mu}{\\sigma})^2$$\n",
    "\n",
    "$$\\beta = \\frac{\\sigma^2}{\\mu}$$\n",
    "\n",
    "The description for the Gamma Distribution defines the parameters $\\gamma$ as the shape parameter and $\\beta$ as the scale parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3\\.** Generate samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 32.5\n",
    "s = 0.325\n",
    "gamma = (mu/s)**2\n",
    "beta = (s**2/mu)\n",
    "\n",
    "xs = np.random.gamma( gamma, beta, 25)\n",
    "print( xs[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 4\\.** Plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 6)) # first element is width, second is height.\n",
    "\n",
    "axes = figure.add_subplot(1, 1, 1)\n",
    "\n",
    "axes.hist( xs, density=True, color=\"DimGray\")\n",
    "axes.set_ylabel( \"Density\")\n",
    "axes.set_xlabel( \"X\")\n",
    "axes.set_title( \"Density for Gamma Distribution (shape=%0.2f, scale=%0.2f)\" % (gamma, beta))\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 5\\.** Print out the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.mean( xs)\n",
    "m2 = np.var( xs)\n",
    "\n",
    "print(\"m1 =\", m1)\n",
    "print(\"m2 =\", m2)\n",
    "\n",
    "gamma_est = (m1**2)/m2\n",
    "beta_est = m2/m1\n",
    "\n",
    "print( \"gamma =\", gamma_est)\n",
    "print( \"beta =\", beta_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6\\.** How far off is the mean you calculate from the $\\mu$ you started off with (in percent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"gamma discrepancy (est/actual) =\", gamma_est/gamma)\n",
    "print( \"beta discrepancy (est/actual) =\", beta_est/beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're off by quite a bit. The gamma estimate is almost 17% larger and the beta is almost 15% smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6\\. From a Systems/Complexity Theory perspective, how might we interpret the variability of a factor like `x`? What might it mean if the variability is low or high? (Why doesn't x just have one value...why does it vary at all?)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Systems Theory (especially Causal Loop Diagrams), we know that we can build pretty complicated models of how the variables in our domain interact both positively and negatively and how they may balance or reinforce each other. We concede that most of the time, we simply cannot get all the relevant data for the domain we want to understand in order to solve whatever our problem is (remember the \"CoNVO\").\n",
    "\n",
    "Now, each observation of $x$ may either be an observation of the *single* system at different *times* (like looking at the economy each month) or observations of many copies of the same system at the same time (like looking at a bunch of people). In either case, the system will be in different states. In the first case because maybe the economy grew, there was a technological innovation (if we modeled it), or there was a natural disaster. In the second case, because all the different copies of the system have different histories and environments. Not to harp on height, but each person may be a different height because of genetics, gene expression, and access to food and types of food throughout their lifetimes so far, and then their age (because we--hopefully--grow as we grow up and--unfortunately--shrink when we age).\n",
    "\n",
    "Now the *dispersion* may be due to a wide number of factors. We are trying to model a complex system with a single distribution. There may be many factors with small effects that cause the dispersion to be large or there may be a few factors with large effects that cause the dispersion to be large.\n",
    "\n",
    "Sometimes this is all we can do (a simple Statistical Model) but sometimes we can build better models (which we'll do later in the semester)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "207px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
